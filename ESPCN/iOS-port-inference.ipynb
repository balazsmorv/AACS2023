{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 09:24:43.736072: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = '/Users/balazsmorvay/Downloads/ESPCN/ESPCN_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(upscale_factor=3, channels=1):\n",
    "    conv_args = {\n",
    "        \"activation\": \"relu\",\n",
    "        \"kernel_initializer\": \"Orthogonal\",\n",
    "        \"padding\": \"same\",\n",
    "    }\n",
    "    # run[\"conv_args\"] = conv_args\n",
    "    inputs = keras.Input(shape=(None, None, channels))\n",
    "    x = layers.Conv2D(64, 5, **conv_args)(inputs)\n",
    "    x = layers.Conv2D(64, 3, **conv_args)(x)\n",
    "    x = layers.Conv2D(32, 3, **conv_args)(x)\n",
    "    x = layers.Conv2D(channels * (upscale_factor ** 2), 3, **conv_args)(x)\n",
    "    outputs = tf.nn.depth_to_space(x, upscale_factor)\n",
    "\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 1)]   0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, None, None, 64)    1664      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, None, None, 32)    18464     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, None, None, 16)    4624      \n",
      "                                                                 \n",
      " tf.nn.depth_to_space (TFOpL  (None, None, None, 1)    0         \n",
      " ambda)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,680\n",
      "Trainable params: 61,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(upscale_factor=4, channels=1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 09:25:13.127560: W tensorflow/core/util/tensor_slice_reader.cc:97] Could not open /Users/balazsmorvay/Downloads/ESPCN/ESPCN_model: FAILED_PRECONDITION: /Users/balazsmorvay/Downloads/ESPCN/ESPCN_model; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fc538750d60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 09:25:30.509140: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2023-05-30 09:25:30.583021: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "Running TensorFlow Graph Passes: 100%|██████████| 6/6 [00:00<00:00, 33.23 passes/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 23/23 [00:00<00:00, 1248.50 ops/s]\n",
      "Running MIL frontend_tensorflow2 pipeline: 100%|██████████| 7/7 [00:00<00:00, 4356.10 passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 57/57 [00:00<00:00, 625.04 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 10/10 [00:00<00:00, 4545.19 passes/s]\n"
     ]
    }
   ],
   "source": [
    "import coremltools as ct\n",
    "\n",
    "mlmodel = ct.convert(\n",
    "                    model,\n",
    "                    source='tensorflow',\n",
    "                    convert_to='mlprogram',\n",
    "                    inputs=[ct.TensorType(shape=(1, 64, 64, 1))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlmodel.save('ESPCN.mlpackage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load pyspng. Defaulting to pillow image backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import sys\n",
    "from fdf256dataset import FDF256Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lowres_image(img, upscale_factor):\n",
    "    \"\"\"Return low-resolution image to use as model input.\"\"\"\n",
    "    return img.resize(\n",
    "        (img.size[0] // upscale_factor, img.size[1] // upscale_factor),\n",
    "        PIL.Image.BICUBIC,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_image(model, img):\n",
    "    \"\"\"Predict the result based on input image and restore the image as RGB.\"\"\"\n",
    "    ycbcr = img.convert(\"YCbCr\")\n",
    "    y, cb, cr = ycbcr.split()\n",
    "    y = img_to_array(y)\n",
    "    y = y.astype(\"float32\") / 255.0\n",
    "\n",
    "    input = np.expand_dims(y, axis=0)\n",
    "    out = model.predict({'input_1': input})\n",
    "\n",
    "    print(out['Identity'].shape)\n",
    "    out_img_y = out['Identity'][0]\n",
    "    out_img_y *= 255.0\n",
    "\n",
    "    # Restore the image in RGB color space.\n",
    "    out_img_y = out_img_y.clip(0, 255)\n",
    "    out_img_y = out_img_y.reshape((np.shape(out_img_y)[0], np.shape(out_img_y)[1]))\n",
    "    out_img_y = PIL.Image.fromarray(np.uint8(out_img_y), mode=\"L\")\n",
    "    out_img_cb = cb.resize(out_img_y.size, PIL.Image.BICUBIC)\n",
    "    out_img_cr = cr.resize(out_img_y.size, PIL.Image.BICUBIC)\n",
    "    out_img = PIL.Image.merge(\"YCbCr\", (out_img_y, out_img_cb, out_img_cr)).convert(\n",
    "        \"RGB\"\n",
    "    )\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:01,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 1)\n",
      "(1, 256, 256, 1)\n",
      "(1, 256, 256, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the entire dataset through the network\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "from einops import rearrange\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "crop_size = 256\n",
    "upscale_factor = 4\n",
    "input_size = crop_size // upscale_factor\n",
    "\n",
    "images = []\n",
    "\n",
    "impaths = '/Users/balazsmorvay/Downloads/val_images'\n",
    "\n",
    "for f in os.listdir(impaths):\n",
    "    if f == '.DS_Store':\n",
    "        continue\n",
    "    p = os.path.join(impaths, f)\n",
    "    image = Image.open(p)\n",
    "    images.append(image)\n",
    "\n",
    "for index, img in tqdm(enumerate(images)):\n",
    "    lowres_input = get_lowres_image(img, upscale_factor)\n",
    "    prediction = upscale_image(mlmodel, lowres_input)\n",
    "    img_array = img_to_array(prediction)\n",
    "    img_array = img_array.astype(\"float32\") / 255.0\n",
    "    plt.imsave(f'{index}.png', img_array)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ios-port",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01697df356223c66d5e30721840d14e58c03c91cb56799e6ad8df82c9e8a8eae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
