{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the keypoints on the original and the upsampled images\n",
    "\n",
    "For the comparison, we're using torchvision's built in, pre-trained keypoint R-CNN network, as the original datasets (FDF256) keypoints were generated with this model.\n",
    "\n",
    "\n",
    "**From PyTorch documentation**:\n",
    "During inference, the model requires only the input tensors, and returns the post-processed predictions as a List[Dict[Tensor]], one for each input image. The fields of the Dict are as follows, where N is the number of detected instances:\n",
    "- boxes (FloatTensor[N, 4]): the predicted boxes in [x1, y1, x2, y2] format, with 0 <= x1 < x2 <= W and 0 <= y1 < y2 <= H.\n",
    "- labels (Int64Tensor[N]): the predicted labels for each instance\n",
    "- scores (Tensor[N]): the scores or each instance\n",
    "- keypoints (FloatTensor[N, K, 3]): the locations of the predicted keypoints, in [x, y, v] format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T07:54:12.719329Z",
     "start_time": "2023-04-25T07:54:10.913520Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import keypointrcnn_resnet50_fpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T07:54:12.723727Z",
     "start_time": "2023-04-25T07:54:12.721688Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T07:54:15.339779Z",
     "start_time": "2023-04-25T07:54:12.725363Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeypointRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(640, 672, 704, 736, 768, 800), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "    (keypoint_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
       "    (keypoint_head): KeypointRCNNHeads(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): ReLU(inplace=True)\n",
       "      (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "    )\n",
       "    (keypoint_predictor): KeypointRCNNPredictor(\n",
       "      (kps_score_lowres): ConvTranspose2d(512, 17, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.detection.keypointrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T07:54:21.887051Z",
     "start_time": "2023-04-25T07:54:15.332771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "torch.Size([2, 17, 3])\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "predictions = model(x)\n",
    "print(predictions[0]['keypoints'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T07:54:21.943841Z",
     "start_time": "2023-04-25T07:54:21.893553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load pyspng. Defaulting to pillow image backend.\n",
      "Dataset loaded from: /datadrive/FDF/dataset/val. Number of samples:6531\n"
     ]
    }
   ],
   "source": [
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "from fdf256dataset import FDF256Dataset\n",
    "\n",
    "dataset_path = '/datadrive/FDF/dataset/val'\n",
    "dataset = FDF256Dataset(dirpath=dataset_path, load_keypoints=True, transform=None, load_impath=True)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=22,\n",
    "                            prefetch_factor=2, persistent_workers=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T07:54:21.948043Z",
     "start_time": "2023-04-25T07:54:21.946722Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_path = '/datadrive/AACS2023/ESPCN/pred_ims'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Annotations\n",
    "\n",
    "The annotation tensor is a 7x2 size tensor where the keypoints are:\n",
    "- nose\n",
    "- left eye\n",
    "- right eye\n",
    "- left ear\n",
    "- right ear\n",
    "- left shoulder\n",
    "- right shoulder\n",
    "\n",
    "The model output tensor is a 17x3 tensor, where the coordinates are the x, y, and visibility (0 is invisible, 1 is visible). The keypoints are:\n",
    "- nose\n",
    "- left eye\n",
    "- right eye\n",
    "- left ear\n",
    "- right ear\n",
    "- left shoulder\n",
    "- right shoulder\n",
    "- left elbow\n",
    "- right elbow\n",
    "- left wrist\n",
    "- right wrist\n",
    "- left hip\n",
    "- right hip\n",
    "- left knee\n",
    "- right knee\n",
    "- left ankle\n",
    "- right ankle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://learnopencv.com/human-pose-estimation-using-keypoint-rcnn-in-pytorch/, rewritten a bit\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def filter_keypoints_per_person(all_keypoints, all_scores, confs, keypoint_threshold=2, conf_threshold=0.9):\n",
    "    # iterate for every person detected\n",
    "    for person_id in range(len(all_keypoints)):\n",
    "      # check the confidence score of the detected person\n",
    "      if confs[person_id]>conf_threshold:\n",
    "        # grab the keypoint-locations for the detected person\n",
    "        keypoints:Tensor = all_keypoints[person_id, ...]\n",
    "        # grab the keypoint-scores for the keypoints\n",
    "        scores: Tensor = all_scores[person_id, ...]\n",
    "        # iterate for every keypoint-score\n",
    "        for kp in range(len(scores)):\n",
    "            # check the confidence score of detected keypoint\n",
    "            if scores[kp] < keypoint_threshold:\n",
    "                # convert the keypoint float-array to a python-list of integers\n",
    "                keypoints[kp, 2] = 0\n",
    "        return keypoints # return the first person with enough confidence\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\displaystyle \\mathrm{DE}(x, y, xhat, yhat, w) = \\frac{\\sqrt{\\left( x - xhat \\right)^{{2}} + \\left( y - yhat \\right)^{{2}}}}{w} $$"
      ],
      "text/plain": [
       "<latexify.frontend.LatexifiedFunction at 0x7f83e4927580>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import latexify\n",
    "import math\n",
    "\n",
    "@latexify.with_latex\n",
    "def DE(x, y, xhat, yhat, w) -> float:\n",
    "    return math.sqrt((x - xhat)**2 + (y - yhat)**2) / w\n",
    "\n",
    "DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(truth, pred):\n",
    "    sum = 0.0\n",
    "    N = 0\n",
    "    for i in range(0, 7):\n",
    "        x, y, v = truth[i]\n",
    "        x_hat, y_hat, v_hat = pred[i]\n",
    "        if v == 0 or v_hat == 0:\n",
    "            continue\n",
    "        sum += ((x - x_hat)**2 + (y - y_hat)**2)\n",
    "        N += 1\n",
    "    \n",
    "    if N == 0:\n",
    "        return None\n",
    "    \n",
    "    return math.sqrt(sum / float(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "kpt_oks_sigmas = np.array([.26, .25, .25, .35, .35, .79, .79])/10.0 * 256# from https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocotools/cocoeval.py#L523\n",
    "\n",
    "\n",
    "def OKS(y_true, y_pred, visibility, bbox_area: float):\n",
    "    SCALE = bbox_area / float(256**2)\n",
    "    # Compute the L2/Euclidean Distance\n",
    "    distances = np.linalg.norm(y_pred - y_true, axis=-1)\n",
    "    # Compute the exponential part of the equation\n",
    "    exp_vector = np.exp(-(distances**2) / (2 * (SCALE**2) * (kpt_oks_sigmas**2)))\n",
    "    # The numerator expression\n",
    "    numerator = np.dot(exp_vector, visibility.astype(bool).astype(int))\n",
    "    # The denominator expression\n",
    "    denominator = np.sum(visibility.astype(bool).astype(int))\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"ESPCN_kpts_compare\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T08:08:32.489052Z",
     "start_time": "2023-04-25T08:08:28.553924Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6531/6531 [08:27<00:00, 12.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------EVALUATION COMPLETE--------\n",
      "Average RMSE: 23.67376179022041\n",
      "Average DEs: [0.01654677528351126, 0.01646996469282185, 0.017457898626482077, 0.03558359172498275, 0.033763407241127134, 0.004134494685056277, 0.0055410073594415145]\n",
      "Average OKS: 0.541443580829174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "from PIL import Image\n",
    "from einops import rearrange\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename=experiment_name,\n",
    "                    filemode='a',\n",
    "                    format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    level=logging.DEBUG)\n",
    "\n",
    "logging.info(\"Running experiment for ESPCN and grounf truth generated image comaprison\")\n",
    "\n",
    "logger = logging.getLogger('ESPCN')\n",
    "\n",
    "sum_rmse = 0.0\n",
    "sum_de = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "sum_oks = 0.0\n",
    "\n",
    "num_rmse = 0\n",
    "num_de = 0\n",
    "num_oks = 0\n",
    "\n",
    "model = model.to('cuda')\n",
    "\n",
    "for i in tqdm(range(len(dataset))):\n",
    "        \n",
    "    original_image = dataset[i]['img'] # tensor of shape (256, 256, 3)\n",
    "    original_kpts = dataset[i]['keypoints'] # tensor of shape (7, 2)\n",
    "    original_kpts = original_kpts * 256 # rescale with image size\n",
    "    # Append the tensor with a visibility flag\n",
    "    visibility = np.where(np.all((original_kpts >= 0) & (original_kpts <= 256), axis=1), 1.0, 0.0)\n",
    "    original_kpts = np.concatenate((original_kpts, visibility.reshape(-1, 1)), axis=1)\n",
    "    \n",
    "    face_bbox = dataset[i][\"face_bbox\"]\n",
    "    x0, y0, x1, y1 = face_bbox\n",
    "    face_width: float = (x1 - x0).item()\n",
    "    face_height: float = (y1 - y0).item()\n",
    "    \n",
    "    imname = str(dataset[i]['impath']).split('/')[-1]\n",
    "    logger.info(\"Evaluating image \" + imname)\n",
    "    #logger.info(\"Original kpts = \" + str(original_kpts))\n",
    "    \n",
    "    scaled_image_path = os.path.join(predictions_path, imname)\n",
    "    with Image.open(scaled_image_path) as fp:\n",
    "        image = np.array(fp, dtype=np.float32)\n",
    "        image = image / 256.0\n",
    "        image = rearrange(image, \"h w c -> c h w\")\n",
    "        image = image[0:3, :, :] # remove the alpha channel, if exists\n",
    "        image = torch.from_numpy(image).to('cuda')\n",
    "    if image is None:\n",
    "        continue\n",
    "    \n",
    "    predictions = model([image])\n",
    "    pred_kpts: Tensor = predictions[0]['keypoints'] # tensor of shape (N, 17, 3)\n",
    "    pred_kpts_scores: Tensor = predictions[0]['keypoints_scores']\n",
    "    pred_scores: Tensor = predictions[0]['scores']\n",
    "    filtered_pred_kpts = filter_keypoints_per_person(pred_kpts, pred_kpts_scores, pred_scores)\n",
    "    if filtered_pred_kpts is not None:\n",
    "        filtered_pred_kpts = filtered_pred_kpts[0:7] # shape (7, 3)\n",
    "    else:\n",
    "        continue\n",
    "    #logger.info(\"Predicted kpts = \" + str(filtered_pred_kpts))\n",
    "    \n",
    "    \n",
    "    # Compare `filtered_pred_kpts` and `original_kpts`\n",
    "    pred = filtered_pred_kpts.cpu().detach().numpy()\n",
    "    \n",
    "    # Detection error\n",
    "    for i in range(0, 7):\n",
    "        x, y, v = original_kpts[i]\n",
    "        x_hat, y_hat, v_hat = pred[i]\n",
    "        if v == 1 and v_hat == 1:\n",
    "            de_i: float = DE(x, y, x_hat, y_hat, face_width)\n",
    "            logger.info(f\"DE for kpt {i} = {de_i}\")\n",
    "            sum_de[i] += de_i\n",
    "            num_de += 1\n",
    "        else:\n",
    "            logger.warning(\"No DE for kpt \" + str(i))    \n",
    "    \n",
    "    # RMSE\n",
    "    rmse = RMSE(original_kpts, pred)\n",
    "    logger.info(\"RMSE = \" + str(rmse))\n",
    "    if rmse is not None:\n",
    "        sum_rmse += rmse\n",
    "        num_rmse += 1\n",
    "    \n",
    "    # OKS\n",
    "    oks: float = OKS(original_kpts[:, 0:1], pred[:, 0:1], original_kpts[:, 2].astype(int), (face_width * face_height))\n",
    "    logger.info(f'OKS = {oks}')\n",
    "    sum_oks += oks\n",
    "    num_oks += 1\n",
    "    \n",
    "    \n",
    "# Compute averages\n",
    "avg_rmse = sum_rmse / num_rmse\n",
    "avg_de = [de_kpt / num_de for de_kpt in sum_de]\n",
    "avg_oks = sum_oks / num_oks\n",
    "\n",
    "logger.info(\"--------EVALUATION COMPLETE--------\")\n",
    "logger.info(f'Average RMSE: {avg_rmse}')\n",
    "logger.info(f'Average DEs: {avg_de}')\n",
    "logger.info(f'Average OKS: {avg_oks}')\n",
    "\n",
    "print(\"--------EVALUATION COMPLETE--------\")\n",
    "print(f'Average RMSE: {avg_rmse}')\n",
    "print(f'Average DEs: {avg_de}')\n",
    "print(f'Average OKS: {avg_oks}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facediffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
